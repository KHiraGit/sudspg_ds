{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機械学習特論 第6回課題 決定木、ランダムフォレスト、アダブーストで アヤメのデータ、MNIST, Fashion-MNIST の分類を比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google colab で実行する場合は、次の行の先頭の # を削除してこのブロックを実行する\n",
    "#!pip install japanize-matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearnデータセットに収録されたiris(アヤメ)のデータセットをロードしてデータフレームを作成\n",
    "def load_iris_data():\n",
    "    data = load_iris()\n",
    "    x = pd.DataFrame(data[\"data\"],columns=data[\"feature_names\"])\n",
    "    y = pd.DataFrame(data[\"target\"],columns=[\"target\"])\n",
    "    return x, y\n",
    "\n",
    "# 手書き文字のデータセットをダウンロードして、実験用データを準備 (70000枚のうち7000枚を利用)\n",
    "def load_mnist_data():\n",
    "    data = fetch_openml('mnist_784', version=1)\n",
    "    _x = np.array(data['data'].astype(np.float32))\n",
    "    _y = np.array(data['target'].astype(np.int32))\n",
    "    _, x, _, y = train_test_split(_x, _y, test_size=0.1, random_state=1)\n",
    "    return x, y\n",
    "\n",
    "# Fashion-MNISTデータセットをダウンロードして、実験用データを準備 (70000枚のうち7000枚を利用)\n",
    "def load_fashion_mnist_data():\n",
    "    data = fetch_openml('Fashion-MNIST')\n",
    "    _x = np.array(data['data'].astype(np.float32))\n",
    "    _y = np.array(data['target'].astype(np.int32))\n",
    "    _, x, _, y = train_test_split(_x, _y, test_size=0.1, random_state=1, stratify=_y) \n",
    "    return x, y\n",
    "\n",
    "# 一括処理のためにデータセットの辞書を作成\n",
    "dataset = {'iris': load_iris_data(), 'mnist': load_mnist_data(), 'fashon-mnist': load_fashion_mnist_data()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一括処理のためにモデルの辞書を作成\n",
    "model = {\n",
    "    # k近傍法のモデル\n",
    "    'kNN(k=3)':\n",
    "    KNeighborsClassifier(n_neighbors=3, # k を指定 (デフォルトは 5)\n",
    "                         weights='uniform',  # 距離を考慮しない(uniform:デフォルト)、する(distance)\n",
    "                         algorithm='auto', # 近傍点計算アルゴリズム (auto:デフォルト,ball_tree,kd_tree,brute)\n",
    "                         leaf_size=30,  # ball_tree,kd_tree指定時のリーフサイズの設定 (デフォルトは 30)\n",
    "                         p=2),  # 距離計算の次元 (2:デフォルト、1)\n",
    "    # svm (kernel=\"linear\", C=1.0) のモデル\n",
    "    'SVC(kernel=\"linear\", C=1)':\n",
    "    svm.SVC(kernel=\"linear\", C=1, max_iter=100000, verbose=True, random_state=1),\n",
    "    # svm (kernel=\"rbf\", C=1) のモデル\n",
    "    'SVC(kernel=\"rbf\", C=1)':\n",
    "    svm.SVC(kernel=\"rbf\", C=1, max_iter=100000, verbose=True, random_state=1),\n",
    "    # 決定木\n",
    "    'DecisionTree(max_depth=10)':\n",
    "    DecisionTreeClassifier(max_depth=10, # 木の深さの最大\n",
    "                                random_state=2), # 乱数シード\n",
    "    # ランダムフォレストのモデル\n",
    "    'randomforest(max_depth=10, n_estimators=10)':\n",
    "    RandomForestClassifier(max_depth=10, # 木の深さの最大\n",
    "                             n_estimators=10, # 木の数\n",
    "                             random_state=2), # 乱数シード\n",
    "    # アダブーストのモデル\n",
    "    'Adaboost(dct(max_depth=10), n_estimators=170)':\n",
    "    AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=10, random_state=1), # ベースモデルを指定\n",
    "                            n_estimators=170, # 木の数\n",
    "                            random_state=1), # 乱数シード\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## dataset:iris  x_train:112 x_test:38 y_train:112 y_test:38\n",
      "dataset:iris model:kNN(k=3) accuracy_score: train_data: 0.94643 test_data: 1.0\n",
      "[LibSVM]dataset:iris model:SVC(kernel=\"linear\", C=1) accuracy_score: train_data: 0.98214 test_data: 1.0\n",
      "[LibSVM]dataset:iris model:SVC(kernel=\"rbf\", C=1) accuracy_score: train_data: 0.97321 test_data: 0.97368\n",
      "dataset:iris model:DecisionTree(max_depth=10) accuracy_score: train_data: 1.0 test_data: 0.97368\n",
      "dataset:iris model:randomforest(max_depth=10, n_estimators=10) accuracy_score: train_data: 0.99107 test_data: 0.97368\n",
      "dataset:iris model:Adaboost(dct(max_depth=10), n_estimators=170) accuracy_score: train_data: 1.0 test_data: 0.97368\n",
      "## dataset:mnist  x_train:5250 x_test:1750 y_train:5250 y_test:1750\n",
      "dataset:mnist model:kNN(k=3) accuracy_score: train_data: 0.96686 test_data: 0.91829\n",
      "[LibSVM]dataset:mnist model:SVC(kernel=\"linear\", C=1) accuracy_score: train_data: 1.0 test_data: 0.89371\n",
      "[LibSVM]dataset:mnist model:SVC(kernel=\"rbf\", C=1) accuracy_score: train_data: 0.98381 test_data: 0.944\n",
      "dataset:mnist model:DecisionTree(max_depth=10) accuracy_score: train_data: 0.95543 test_data: 0.75829\n",
      "dataset:mnist model:randomforest(max_depth=10, n_estimators=10) accuracy_score: train_data: 0.98286 test_data: 0.88171\n",
      "dataset:mnist model:Adaboost(dct(max_depth=10), n_estimators=170) accuracy_score: train_data: 1.0 test_data: 0.92286\n",
      "## dataset:fashon-mnist  x_train:5250 x_test:1750 y_train:5250 y_test:1750\n",
      "dataset:fashon-mnist model:kNN(k=3) accuracy_score: train_data: 0.89467 test_data: 0.80857\n",
      "[LibSVM]dataset:fashon-mnist model:SVC(kernel=\"linear\", C=1) accuracy_score: train_data: 1.0 test_data: 0.81086\n",
      "[LibSVM]dataset:fashon-mnist model:SVC(kernel=\"rbf\", C=1) accuracy_score: train_data: 0.89371 test_data: 0.84571\n",
      "dataset:fashon-mnist model:DecisionTree(max_depth=10) accuracy_score: train_data: 0.89124 test_data: 0.76686\n",
      "dataset:fashon-mnist model:randomforest(max_depth=10, n_estimators=10) accuracy_score: train_data: 0.93067 test_data: 0.82629\n",
      "dataset:fashon-mnist model:Adaboost(dct(max_depth=10), n_estimators=170) accuracy_score: train_data: 1.0 test_data: 0.84057\n"
     ]
    }
   ],
   "source": [
    "# 辞書に格納したデータセットそれぞれについて性能を確認\n",
    "for dataset_key in dataset.keys():\n",
    "    # データを学習用と検証用に分割\n",
    "    x, y = dataset[dataset_key]\n",
    "    x_train, x_test, y_train, y_test = \\\n",
    "        train_test_split(x, y, test_size=0.25, random_state=1) # 検証用データに25%を割当て\n",
    "    print(f'## dataset:{dataset_key} ',\n",
    "          f'x_train:{len(x_train)} x_test:{len(x_test)} y_train:{len(y_train)} y_test:{len(y_test)}')\n",
    "\n",
    "    # 辞書に格納したモデルそれぞれについて性能を測定\n",
    "    for model_key in model.keys():\n",
    "        # 学習用データを利用してモデルを学習\n",
    "        clf = model[model_key]\n",
    "        clf = clf.fit(x_train, np.array(y_train).ravel()) \n",
    "\n",
    "        # 学習したモデルの性能(正答率)を学習用データと検証用データで評価\n",
    "        predict_train = clf.predict(x_train)\n",
    "        train_score = metrics.accuracy_score(y_train, predict_train)\n",
    "        predict_test = clf.predict(x_test)\n",
    "        test_score = metrics.accuracy_score(y_test, predict_test)\n",
    "        print(f'dataset:{dataset_key} model:{model_key}', \n",
    "            f'accuracy_score: train_data:{train_score: 0.5} test_data:{test_score: 0.5}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## dataset:iris  x_train:112 x_test:38 y_train:112 y_test:38\n",
      "# no scaling\n",
      "dataset:iris model:kNN(k=3) accuracy_score: train_data: 0.94643 test_data: 1.0\n",
      "[LibSVM]dataset:iris model:SVC(kernel=\"linear\", C=1) accuracy_score: train_data: 0.98214 test_data: 1.0\n",
      "[LibSVM]dataset:iris model:SVC(kernel=\"rbf\", C=1) accuracy_score: train_data: 0.97321 test_data: 0.97368\n",
      "dataset:iris model:DecisionTree(max_depth=10) accuracy_score: train_data: 1.0 test_data: 0.97368\n",
      "dataset:iris model:randomforest(max_depth=10, n_estimators=10) accuracy_score: train_data: 0.99107 test_data: 0.97368\n",
      "dataset:iris model:Adaboost(dct(max_depth=10), n_estimators=170) accuracy_score: train_data: 1.0 test_data: 0.97368\n",
      "# with scaling\n",
      "dataset:iris model:kNN(k=3) accuracy_score: train_data: 0.94643 test_data: 1.0\n",
      "[LibSVM]dataset:iris model:SVC(kernel=\"linear\", C=1) accuracy_score: train_data: 0.96429 test_data: 0.97368\n",
      "[LibSVM]dataset:iris model:SVC(kernel=\"rbf\", C=1) accuracy_score: train_data: 0.97321 test_data: 0.97368\n",
      "dataset:iris model:DecisionTree(max_depth=10) accuracy_score: train_data: 1.0 test_data: 0.97368\n",
      "dataset:iris model:randomforest(max_depth=10, n_estimators=10) accuracy_score: train_data: 0.99107 test_data: 0.97368\n",
      "dataset:iris model:Adaboost(dct(max_depth=10), n_estimators=170) accuracy_score: train_data: 1.0 test_data: 0.97368\n",
      "## dataset:mnist  x_train:5250 x_test:1750 y_train:5250 y_test:1750\n",
      "# no scaling\n",
      "dataset:mnist model:kNN(k=3) accuracy_score: train_data: 0.96686 test_data: 0.91829\n",
      "[LibSVM]dataset:mnist model:SVC(kernel=\"linear\", C=1) accuracy_score: train_data: 1.0 test_data: 0.89371\n",
      "[LibSVM]dataset:mnist model:SVC(kernel=\"rbf\", C=1) accuracy_score: train_data: 0.98381 test_data: 0.944\n",
      "dataset:mnist model:DecisionTree(max_depth=10) accuracy_score: train_data: 0.95543 test_data: 0.75829\n",
      "dataset:mnist model:randomforest(max_depth=10, n_estimators=10) accuracy_score: train_data: 0.98286 test_data: 0.88171\n",
      "dataset:mnist model:Adaboost(dct(max_depth=10), n_estimators=170) accuracy_score: train_data: 1.0 test_data: 0.92286\n",
      "# with scaling\n",
      "dataset:mnist model:kNN(k=3) accuracy_score: train_data: 0.94476 test_data: 0.88857\n",
      "[LibSVM]dataset:mnist model:SVC(kernel=\"linear\", C=1) accuracy_score: train_data: 1.0 test_data: 0.88914\n",
      "[LibSVM]dataset:mnist model:SVC(kernel=\"rbf\", C=1) accuracy_score: train_data: 0.98095 test_data: 0.91429\n",
      "dataset:mnist model:DecisionTree(max_depth=10) accuracy_score: train_data: 0.95543 test_data: 0.75829\n",
      "dataset:mnist model:randomforest(max_depth=10, n_estimators=10) accuracy_score: train_data: 0.98286 test_data: 0.88171\n",
      "dataset:mnist model:Adaboost(dct(max_depth=10), n_estimators=170) accuracy_score: train_data: 1.0 test_data: 0.92286\n",
      "## dataset:fashon-mnist  x_train:5250 x_test:1750 y_train:5250 y_test:1750\n",
      "# no scaling\n",
      "dataset:fashon-mnist model:kNN(k=3) accuracy_score: train_data: 0.89467 test_data: 0.80857\n",
      "[LibSVM]dataset:fashon-mnist model:SVC(kernel=\"linear\", C=1) accuracy_score: train_data: 1.0 test_data: 0.81086\n",
      "[LibSVM]dataset:fashon-mnist model:SVC(kernel=\"rbf\", C=1) accuracy_score: train_data: 0.89371 test_data: 0.84571\n",
      "dataset:fashon-mnist model:DecisionTree(max_depth=10) accuracy_score: train_data: 0.89124 test_data: 0.76686\n",
      "dataset:fashon-mnist model:randomforest(max_depth=10, n_estimators=10) accuracy_score: train_data: 0.93067 test_data: 0.82629\n",
      "dataset:fashon-mnist model:Adaboost(dct(max_depth=10), n_estimators=170) accuracy_score: train_data: 1.0 test_data: 0.84057\n",
      "# with scaling\n",
      "dataset:fashon-mnist model:kNN(k=3) accuracy_score: train_data: 0.89619 test_data: 0.81371\n",
      "[LibSVM]dataset:fashon-mnist model:SVC(kernel=\"linear\", C=1) accuracy_score: train_data: 0.99981 test_data: 0.80514\n",
      "[LibSVM]dataset:fashon-mnist model:SVC(kernel=\"rbf\", C=1) accuracy_score: train_data: 0.91562 test_data: 0.84629\n",
      "dataset:fashon-mnist model:DecisionTree(max_depth=10) accuracy_score: train_data: 0.89124 test_data: 0.76686\n",
      "dataset:fashon-mnist model:randomforest(max_depth=10, n_estimators=10) accuracy_score: train_data: 0.93086 test_data: 0.82629\n",
      "dataset:fashon-mnist model:Adaboost(dct(max_depth=10), n_estimators=170) accuracy_score: train_data: 1.0 test_data: 0.84114\n"
     ]
    }
   ],
   "source": [
    "# 辞書に格納したデータセットそれぞれについて性能を確認\n",
    "for dataset_key in dataset.keys():\n",
    "    # データを学習用と検証用に分割\n",
    "    x, y = dataset[dataset_key]\n",
    "    x_train, x_test, y_train, y_test = \\\n",
    "        train_test_split(x, y, test_size=0.25, random_state=1) # 検証用データに25%を割当て\n",
    "    print(f'## dataset:{dataset_key} ',\n",
    "          f'x_train:{len(x_train)} x_test:{len(x_test)} y_train:{len(y_train)} y_test:{len(y_test)}')\n",
    "\n",
    "    # データ標準化なしで性能を測定\n",
    "    print('# no scaling')\n",
    "    # 辞書に格納したモデルそれぞれについて性能を測定\n",
    "    for model_key in model.keys():\n",
    "        # 学習用データを利用してモデルを学習\n",
    "        clf = model[model_key]\n",
    "        clf = clf.fit(x_train, np.array(y_train).ravel()) \n",
    "\n",
    "        # 学習したモデルの性能(正答率)を学習用データと検証用データで評価\n",
    "        predict_train = clf.predict(x_train)\n",
    "        train_score = metrics.accuracy_score(y_train, predict_train)\n",
    "        predict_test = clf.predict(x_test)\n",
    "        test_score = metrics.accuracy_score(y_test, predict_test)\n",
    "        print(f'dataset:{dataset_key} model:{model_key}', \n",
    "            f'accuracy_score: train_data:{train_score: 0.5} test_data:{test_score: 0.5}')\n",
    "\n",
    "    # データを標準化\n",
    "    print('# with scaling')\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    # 辞書に格納したモデルそれぞれについて性能を測定\n",
    "    for model_key in model.keys():\n",
    "        # 学習用データを利用してモデルを学習\n",
    "        clf = model[model_key]\n",
    "        clf = clf.fit(x_train, np.array(y_train).ravel()) \n",
    "\n",
    "        # 学習したモデルの性能(正答率)を学習用データと検証用データで評価\n",
    "        predict_train = clf.predict(x_train)\n",
    "        train_score = metrics.accuracy_score(y_train, predict_train)\n",
    "        predict_test = clf.predict(x_test)\n",
    "        test_score = metrics.accuracy_score(y_test, predict_test)\n",
    "        print(f'dataset:{dataset_key} model:{model_key}', \n",
    "            f'accuracy_score: train_data:{train_score: 0.5} test_data:{test_score: 0.5}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18ef0afcf35f1452430268c7ef685ac367525865953635d3b087fb3264879c09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
